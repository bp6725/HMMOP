{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../POS_tagging/\")\n",
    "sys.path.append(\"../../../pomegranate/\")\n",
    "sys.path.append(r\"../../../WhoCell\\pomegranate\")\n",
    "sys.path.append(r\"../../../WhoCell\")\n",
    "sys.path.append(r\"../../../WhoCell/\")\n",
    "sys.path.append(r\"../../../WhoCell/who_cell/\")\n",
    "sys.path.append(r\"../../../WhoCell/who_cell/models/\")\n",
    "sys.path.append(r\"../../../WhoCell/who_cell/simulation/\")\n",
    "sys.path.append(r\"../../../WhoCell/who_cell/experiments/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "from collections import Counter\n",
    "from IPython.core.display import HTML\n",
    "from itertools import chain\n",
    "from collections import Counter, defaultdict\n",
    "from helpers import show_model, Dataset\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from functools import reduce\n",
    "import pickle\n",
    "\n",
    "from pomegranate import State, HiddenMarkovModel, DiscreteDistribution\n",
    "\n",
    "from simulation_for_gibbs import Simulator_for_Gibbs\n",
    "from gibbs_sampler import GibbsSampler\n",
    "from experiment_report import ExperimentReport \n",
    "from gibbs_experiments import GibbsExperiment\n",
    "from pos_data_builder import PosDataBuilder\n",
    "from pos_code_base import PosCodeBase\n",
    "from em_sequence_labeling import EmSequenceLabeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"shell_port\": 55059,\n",
      "  \"iopub_port\": 39709,\n",
      "  \"stdin_port\": 47695,\n",
      "  \"control_port\": 49539,\n",
      "  \"hb_port\": 44215,\n",
      "  \"ip\": \"127.0.0.1\",\n",
      "  \"key\": \"fd44b18a-9ba6e7b4c71af682f5025dd7\",\n",
      "  \"transport\": \"tcp\",\n",
      "  \"signature_scheme\": \"hmac-sha256\",\n",
      "  \"kernel_name\": \"\"\n",
      "}\n",
      "\n",
      "Paste the above JSON into a file, and connect with:\n",
      "    $> jupyter <app> --existing <file>\n",
      "or, if you are local, you can connect with just:\n",
      "    $> jupyter <app> --existing kernel-7c5fbb8d-899e-49e7-b077-da8912056e86.json\n",
      "or even just:\n",
      "    $> jupyter <app> --existing\n",
      "if this is the most recent Jupyter kernel you have started.\n"
     ]
    }
   ],
   "source": [
    "%connect_info\n",
    "%load_ext autoreload\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load experiments sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_builder = PosDataBuilder()\n",
    "code_base = PosCodeBase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build experiment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The experiment details -   \n",
    "\n",
    "Our data :   \n",
    "1)Training data : labeled sentences\n",
    "2)Test set - the same\n",
    "\n",
    "Experiment :  \n",
    "1)We will use the training set labels for few observations Markov chain - not hidden! by using the states labels as emissions.  \n",
    "2)Then we learn the emissions from the training set  \n",
    "3)We will predict the labels on the test set   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pc = 0.5\n",
    "\n",
    "test_set_words, test_set_tags,train_set_words, train_set_tags = data_builder.get_experiment_sets_from_real_data(pc,False)\n",
    "all_states = data_builder._build_emissions_probabilites().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5309/1549267804.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_builder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfew_obs_test_set_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "data_builder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions_probs,transitions_probs_df = data_builder.get_known_transitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_iters = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning without \"few observations\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "emm_probs = {state:{state:1} for state in all_states}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▍                                       | 2/20 [00:53<08:05, 26.99s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5309/1387190511.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\"state_order_for_plot\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdata_builder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTATE_ORDER_TO_PLOT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \"title\":\"Naive MM\"}\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mfirst_experiment_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcode_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pos_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfirst_experiment_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Repos/Few_observations_hmm/WhoCell/benchmarks/POS_tagging/pos_code_base.py\u001b[0m in \u001b[0;36mrun_pos_experiment\u001b[0;34m(test_set_words, start_probs, emms_probs, number_of_iters, N, description, known_transitions, title, is_only_observed, comper_transitions, comper_transitions_title, state_order_for_plot)\u001b[0m\n\u001b[1;32m     20\u001b[0m                            comper_transitions, comper_transitions_title, state_order_for_plot):\n\u001b[1;32m     21\u001b[0m         \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGibbsSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mis_only_observed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         sampled_transitions, ws, transitions, states_picked_by_w,all_alphas = gs.sample_known_emissions(test_set_words,\n\u001b[0m\u001b[1;32m     23\u001b[0m                                                                                              \u001b[0mstart_probs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                                                                                              \u001b[0memms_probs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repos/Few_observations_hmm/WhoCell/benchmarks/POS_tagging/../../../WhoCell/who_cell/models/gibbs_sampler.py\u001b[0m in \u001b[0;36msample_known_emissions\u001b[0;34m(self, all_relvent_observations, start_probs, emissions_table, Ng_iters, w_smapler_n_iter, N, is_mh)\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0m_states_picked_by_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mws\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_walk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m                 curr_walk,alpha2 = self.sample_walk_from_params(all_relvent_observations, N,\n\u001b[0m\u001b[1;32m    251\u001b[0m                                                          \u001b[0memissions_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_probs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                                                          \u001b[0mcurr_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_trans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repos/Few_observations_hmm/WhoCell/benchmarks/POS_tagging/../../../WhoCell/who_cell/models/utils.py\u001b[0m in \u001b[0;36m_update_based_on_alpha\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mis_known_emissions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknown_emissions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurr_walk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             old_prob = Utils._calc_probability_function_for_alpha(observations, curr_trans, curr_w, curr_walk,\n\u001b[0m\u001b[1;32m     34\u001b[0m                                                                          \u001b[0mcurr_mu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_mue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                                                                          \u001b[0mknown_emissions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mknown_emissions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repos/Few_observations_hmm/WhoCell/benchmarks/POS_tagging/../../../WhoCell/who_cell/models/utils.py\u001b[0m in \u001b[0;36m_calc_probability_function_for_alpha\u001b[0;34m(all_relvent_observations, curr_trans, curr_w, curr_walk, curr_mu, known_emissions, is_known_emissions)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0m_walk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurr_walk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0m_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__calc_probability_function_per_traj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_trans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_walk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknown_emissions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mis_known_emissions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0mprobs_per_traj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs_per_traj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repos/Few_observations_hmm/WhoCell/benchmarks/POS_tagging/../../../WhoCell/who_cell/models/utils.py\u001b[0m in \u001b[0;36m__calc_probability_function_per_traj\u001b[0;34m(traj, _trans, _w, _walk, curr_mu, known_emissions, is_known_emissions)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_known_emissions\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0memissions_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mknown_emissions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_walk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m__w\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m__w\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0mlog_emissions_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memissions_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 emissions_prob = [Utils.normpdf(traj[k],known_emissions[_walk[__w]][0],known_emissions[_walk[__w]][1])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "first_experiment_args = {\"test_set_words\":train_set_tags,\n",
    "\"start_probs\":data_builder._build_starting_probabilites(),\n",
    "\"emms_probs\":emm_probs,\n",
    "\"number_of_iters\":number_of_iters,\n",
    "\"N\":2,\n",
    "\"is_only_observed\":\"observed\",\n",
    "\"description\":\"P(C) = 1\",\n",
    "\"known_transitions\":None,\n",
    "\"comper_transitions\":None,\n",
    "\"comper_transitions_title\" :None,\n",
    "\"state_order_for_plot\":data_builder.STATE_ORDER_TO_PLOT,\n",
    "\"title\":\"Naive MM\"}\n",
    "first_experiment_results = code_base.run_pos_experiment(**first_experiment_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## learning when the expected trajectory is twice the length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_known_N = [2*len(seq) for seq in train_set_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second_experiment_args = {\"test_set_words\":train_set_tags,\n",
    "# \"start_probs\":data_builder._build_starting_probabilites(),\n",
    "# \"emms_probs\":emm_probs,\n",
    "# \"number_of_iters\":number_of_iters,\n",
    "# \"N\":_known_N,\n",
    "# \"is_only_observed\":\"all\",\n",
    "# \"description\":\"P(C) = 1\",\n",
    "# \"known_transitions\":None,\n",
    "# \"comper_transitions\":None,\n",
    "# \"comper_transitions_title\" :None,\n",
    "# \"state_order_for_plot\":data_builder.STATE_ORDER_TO_PLOT,\n",
    "# \"title\":\"few obs\"}\n",
    "# second_experiment_results = code_base.run_pos_experiment(**second_experiment_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## learning when the expected trajectory is twice the length only observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_experiment_args = {\"test_set_words\":train_set_tags,\n",
    "\"start_probs\":data_builder._build_starting_probabilites(),\n",
    "\"emms_probs\":emm_probs,\n",
    "\"number_of_iters\":number_of_iters,\n",
    "\"N\":_known_N,\n",
    "\"is_only_observed\":\"extended\",\n",
    "\"description\":\"P(C) = 1\",\n",
    "\"known_transitions\":None,\n",
    "\"comper_transitions\":None,\n",
    "\"comper_transitions_title\" :None,\n",
    "\"state_order_for_plot\":data_builder.STATE_ORDER_TO_PLOT,\n",
    "\"title\":\"few obs only seen\"}\n",
    "third_experiment_results = code_base.run_pos_experiment(**third_experiment_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# measures and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pome_model_from_trnaisiotns(predicted_transitions,words_emms_probs,start_probs,all_states):\n",
    "    states_name_to_state_mapping = {state:State(DiscreteDistribution(words_emms_probs[state]),state) for state in all_states}\n",
    "\n",
    "    _model = HiddenMarkovModel()\n",
    "    for _from,_tos in predicted_transitions.items() : \n",
    "        if _from == \"start\" : \n",
    "            for state in all_states : \n",
    "                _to_state = states_name_to_state_mapping[state]\n",
    "                _model.add_transition(_model.start,_to_state,start_probs[state])\n",
    "            continue\n",
    "        for _to,val in _tos.items() :\n",
    "            if _to == 'end' : continue\n",
    "            _to_state = states_name_to_state_mapping[_to]\n",
    "            \n",
    "            _from_state = states_name_to_state_mapping[_from]\n",
    "            _model.add_transition(_from_state,_to_state,val)\n",
    "\n",
    "    _model.bake()\n",
    "    return _model\n",
    "\n",
    "def calculate_error_pome(predicted_transitions,test_set_words,test_set_tags,words_emms_probs,start_probs,all_states,unknown_words):\n",
    "    pome_model = build_pome_model_from_trnaisiotns(predicted_transitions,words_emms_probs,start_probs,all_states)\n",
    "    states_name_list = [state.name for state in pome_model.states]\n",
    "\n",
    "    errors = []\n",
    "    for sent_words,sent_tags in zip(test_set_words,test_set_tags) :\n",
    "        sent_words = [(word if word not in unknown_words else None) for word in sent_words]\n",
    "        _predicted = pome_model.predict(sent_words)\n",
    "        predicted_tags = [states_name_list[i] for i in _predicted]\n",
    "        error = sum([i!=j for i,j in zip(sent_tags,predicted_tags)])\n",
    "        errors.append(error)\n",
    "    \n",
    "    amount_of_tags = sum(list(map(len,test_set_tags)))\n",
    "    return np.sum(errors)/amount_of_tags\n",
    "\n",
    "def calculate_error_gibbs(N,predicted_transitions,test_set_words,\n",
    "                          test_set_tags,words_emms_probs,start_probs,\n",
    "                          all_states):    \n",
    "    \n",
    "    _test_set_words = list(filter(lambda x:len(x)<60,test_set_words))\n",
    "    _test_set_tags = list(filter(lambda x:len(x)<60,test_set_tags))\n",
    "    gibbs_sampler = GibbsSampler(N,multi_process=True)\n",
    "    all_states_picked_by_w = EmSequenceLabeling.sequence_labeling_known_emissions(_test_set_words,\n",
    "                                                                                   predicted_transitions,\n",
    "                                                                                   start_probs,\n",
    "                               words_emms_probs, 5, N = N)\n",
    "    \n",
    "    errors = []\n",
    "    for known_tags,predicted_tags in zip(_test_set_tags,all_states_picked_by_w[-1]) :\n",
    "        error = sum([i!=j for i,j in zip(known_tags,predicted_tags)])\n",
    "        errors.append(error)\n",
    "    \n",
    "    amount_of_tags = sum(list(map(len,_test_set_tags)))\n",
    "    return np.sum(errors)/amount_of_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_df_results(model_results_df,title):\n",
    "    \n",
    "    fig, sub = plt.subplots(1,1,figsize=(8, 8))\n",
    "    \n",
    "\n",
    "    sns.lineplot(data=model_results_df, ax=sub, legend='full', dashes=False)\n",
    "    sub.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    sub.set_title(title)\n",
    "    sub.set_xlabel(\"iter\")\n",
    "    sub.set_ylabel(f\"Hamming distance over test set\")\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.8)\n",
    "    plt.subplots_adjust(wspace=0.8)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def build_and_plot_results(experiments_results,experiments_params,test_set_words,test_set_tags,data_builder,all_states): \n",
    "    words_emms_probs = data_builder._build_emissions_probabilites()\n",
    "\n",
    "    all_words_in_test_set = data_builder.row_data.vocab\n",
    "    all_known_words = frozenset(chain(*[val for val in words_emms_probs.values()]))\n",
    "    unknown_words = (all_words_in_test_set - all_known_words)\n",
    "    \n",
    "    words_emms_probs = data_builder._build_emissions_probabilites()\n",
    "    start_probs = data_builder._build_starting_probabilites()\n",
    "    \n",
    "    sentences_length = list(map(len,test_set_tags))\n",
    "    \n",
    "#     with open(\"build_and_plot_data.pkl\",'wb') as f : \n",
    "#         pickle.dump((experiments_results,experiments_params,test_set_words,test_set_tags,list(all_states),words_emms_probs,all_words_in_test_set,words_emms_probs,start_probs),f)\n",
    "\n",
    "    \n",
    "    pomegranate_errors = {}\n",
    "    missing_obs_errors = {}\n",
    "    gibbs_no_missing_errors = {}\n",
    "    \n",
    "    n_iter_exp = len(experiments_results[0]['transitions'])\n",
    "    transitions_to_pick = sorted(list(set(list(range(0,n_iter_exp,15)) + [n_iter_exp-1])))\n",
    "    print(transitions_to_pick)\n",
    "    for i,(exp_res,exp_args) in enumerate(zip(experiments_results,experiments_params)) :\n",
    "        transitions = exp_res['transitions']\n",
    "        fewer_transitions = [transitions[i] for i in transitions_to_pick]\n",
    "        \n",
    "        title = exp_args['title']\n",
    "#         pomegranate_error_per_experiment = [calculate_error_pome(_trans,\n",
    "#                                                                  test_set_words,test_set_tags,\n",
    "#                                                                  words_emms_probs,\n",
    "#                                                                  start_probs,\n",
    "#                                                                  all_states,\n",
    "#                                                                  unknown_words) for _trans in fewer_transitions]\n",
    "        \n",
    "#         pomegranate_errors[title] = pomegranate_error_per_experiment\n",
    "        \n",
    "        gibbs_missing_error_per_experiment = [calculate_error_gibbs(exp_args[\"N\"],\n",
    "                                                                    _trans,\n",
    "                                                                    test_set_words,test_set_tags,\n",
    "                                                                    words_emms_probs,start_probs,\n",
    "                                                                    all_states) for _trans in fewer_transitions]\n",
    "        missing_obs_errors[title] = gibbs_missing_error_per_experiment\n",
    "        \n",
    "        gibbs_full_error_per_experiment = [calculate_error_gibbs(2,_trans,test_set_words,test_set_tags,\n",
    "                                                                    words_emms_probs,start_probs,all_states) \n",
    "                                           for _trans in fewer_transitions]\n",
    "        gibbs_no_missing_errors[title] = gibbs_full_error_per_experiment\n",
    "        \n",
    "        \n",
    "#     pome_results_df = pd.DataFrame(pomegranate_errors)\n",
    "    gibbs_mising_results_df = pd.DataFrame(missing_obs_errors)\n",
    "    gibbs_full_results_df = pd.DataFrame(gibbs_no_missing_errors)\n",
    "    \n",
    "#     plot_df_results(pome_results_df,\"inference pomegranate using viterbi\")\n",
    "    plot_df_results(gibbs_mising_results_df,\"inference Gibbs counting for missing observations \")\n",
    "    plot_df_results(gibbs_full_results_df,\"inference Gibbs not counting for missing observations\")\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_results = [first_experiment_results,third_experiment_results]\n",
    "experiments_params = [first_experiment_args,third_experiment_args]\n",
    "\n",
    "build_and_plot_results(experiments_results,experiments_params,\n",
    "                       test_set_words,test_set_tags,data_builder,\n",
    "                       all_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_results[0]['transitions'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_results = [first_experiment_results,second_experiment_results]\n",
    "experiments_params = [first_experiment_args,second_experiment_args]\n",
    "\n",
    "build_and_plot_results(experiments_results,experiments_params,\n",
    "                       test_set_words,test_set_tags,data_builder,\n",
    "                       all_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter_exp = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
