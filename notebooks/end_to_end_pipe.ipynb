{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import functools\n",
    "import copy\n",
    "\n",
    "import pomegranate\n",
    "from pomegranate import HiddenMarkovModel ,State\n",
    "from pomegranate.distributions import IndependentComponentsDistribution\n",
    "from pomegranate.distributions import NormalDistribution,DiscreteDistribution\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build the meta network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params :\n",
    "# n_dim_of_chain=8\n",
    "# n_of_chains = 5\n",
    "# possible_number_of_walks = [1,2,3,4]\n",
    "\n",
    "n_dim_of_chain=3\n",
    "n_of_chains = 2\n",
    "possible_number_of_walks = [1,2]\n",
    "number_of_possible_states_limit = 10000000\n",
    "chance_to_be_in_path = 1.1\n",
    "prob_of_dim=0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0,
     20,
     34,
     41
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 7977.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "def generate_all_binarys(n, arr, i): \n",
    "    if i==n :\n",
    "        all_binarys.append(np.nonzero(arr.copy())[0].tolist())\n",
    "        return \n",
    "\n",
    "    arr[i] = 0\n",
    "    generate_all_binarys(n, arr, i + 1)  \n",
    "\n",
    "    arr[i] = 1\n",
    "    generate_all_binarys(n, arr, i + 1) \n",
    "\n",
    "def build_IX_mock(n, possible_number_of_walks):\n",
    "    imx_possible_walks = {}\n",
    "\n",
    "    if (max(possible_number_of_walks) + 1 ) > n :\n",
    "        raise Exception( f\"there is no {max(possible_number_of_walks)} possible\")\n",
    "\n",
    "    cell_idx = 0\n",
    "    while cell_idx < n :\n",
    "        number_of_walks = np.random.choice(possible_number_of_walks)\n",
    "        walks_idx = np.random.choice(range(n), number_of_walks, False)\n",
    "        walks_idx = np.append(walks_idx, np.array(cell_idx))\n",
    "        walks_idx = np.unique(walks_idx)\n",
    "\n",
    "        if len(walks_idx) != (number_of_walks + 1) :\n",
    "            continue\n",
    "\n",
    "        imx_possible_walks[cell_idx] = walks_idx\n",
    "        cell_idx = cell_idx + 1\n",
    "    return imx_possible_walks\n",
    "        \n",
    "def build_network_from_IX(n,all_binarys,imx_possible_walks) : \n",
    "    network_dic = {} #key:cell vec, value : all conncted cell vecs\n",
    "    pathway_network = {}\n",
    "    \n",
    "    for cell_vec in tqdm(all_binarys) : \n",
    "        if len(cell_vec) == 0  :\n",
    "            continue\n",
    "\n",
    "        possible_walk_for_idx_matrix = [imx_possible_walks[cell_idx] for cell_idx in cell_vec]\n",
    "        all_possible_walks_from_cell = [frozenset(comb) for comb in itertools.product(*possible_walk_for_idx_matrix)]\n",
    "        \n",
    "        #we dont want transition to the same state\n",
    "        non_cyclic_walks = [walk for walk in all_possible_walks_from_cell if tuple(walk) != tuple(cell_vec)]\n",
    "       \n",
    "        network_dic[tuple(cell_vec)] = non_cyclic_walks\n",
    "    return network_dic\n",
    "\n",
    "def build_model_networks(n_of_chains,n,all_binarys,imx_possible_walks) : \n",
    "    model_networks = {}\n",
    "    for i in range(n_of_chains) : \n",
    "        _net_walks = build_network_from_IX(n,all_binarys,imx_possible_walks)\n",
    "        model_networks[i] = _net_walks\n",
    "    return model_networks\n",
    "\n",
    "def build_pathways_mock(imx_possible_walks) : \n",
    "    hard_walk_to_pathways_map = {}\n",
    "    for vec in imx_possible_walks : \n",
    "        path = np.random.choice([1,2,3,4])\n",
    "        hard_cells_to_pathways_map[tuple(vec)] = path\n",
    "    return hard_walk_to_pathways_map\n",
    "\n",
    "all_binarys = [] \n",
    "generate_all_binarys(n_dim_of_chain,[None]*n_dim_of_chain,0)\n",
    "imx_possible_walks = build_IX_mock(n_dim_of_chain,possible_number_of_walks)\n",
    "model_networks = build_model_networks(n_of_chains,n_dim_of_chain,all_binarys,imx_possible_walks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the naive comb of states across chains\n",
    "all_curr_state_comb_between_networks = itertools.product(*[network for network in model_networks.values()])\n",
    "#we belive we can filter base on the real data\n",
    "filtered_curr_state_comb_between_networks = (itertools.islice(all_curr_state_comb_between_networks,number_of_possible_states_limit))\n",
    "filtered_curr_state_comb_between_networks_1,filtered_curr_state_comb_between_networks_2 = itertools.tee(filtered_curr_state_comb_between_networks)\n",
    "\n",
    "#now we need to find all possible combinations of walks : \n",
    "#we start by building all comb of walks across chains for all comb of states across chain\n",
    "all_walks_across_chains = (map(lambda comb:[model_networks[net_idx][chain_state] for net_idx,chain_state in enumerate(comb)],filtered_curr_state_comb_between_networks_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def is_walk_in_path(x,_path,chance_to_be_in_path):\n",
    "    return random.random() < chance_to_be_in_path\n",
    "\n",
    "def return_filtered_walks_per_curr_chain(_walks_per_curr_chain,path,chance_to_be_in_path):\n",
    "    return list(map(lambda walk:list(filter(lambda x:is_walk_in_path(x,path,chance_to_be_in_path),walk)),_walks_per_curr_chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#we now build diffrent stream for each pathway - **only comb where all the walks are in the same pathway are possible **\n",
    "def filter_comb_of_walks_across_chains(_walks_per_curr_comb,chance_to_be_in_path):\n",
    "    all_combs_of_walks_all_paths = []\n",
    "    for _path in [1,2,3,4,5] : \n",
    "\n",
    "        #keep only walks in the pathway    \n",
    "        _walks_per_curr_comb_in_path = return_filtered_walks_per_curr_chain(_walks_per_curr_comb,_path,chance_to_be_in_path)\n",
    "        \n",
    "        #its smart to filter out first comb of walks where there is at least one chain with no walk in this pathway :\n",
    "        if any([len(_walks)==0 for _walks in _walks_per_curr_comb_in_path]):\n",
    "            continue\n",
    "\n",
    "        _combs_of_walks = list(itertools.product(*_walks_per_curr_comb_in_path))\n",
    "        for _comb in  _combs_of_walks : \n",
    "            if _comb not in all_combs_of_walks_all_paths :\n",
    "                all_combs_of_walks_all_paths = all_combs_of_walks_all_paths +  [_comb]\n",
    "    return all_combs_of_walks_all_paths\n",
    "\n",
    "filt_comb_walks_across_chains = (map(lambda _walks_per_curr_comb:filter_comb_of_walks_across_chains(_walks_per_curr_comb,chance_to_be_in_path),all_walks_across_chains) )\n",
    "\n",
    "#zip the combinations of states with the comb of walks \n",
    "state_comb_to_walks_comb = zip(filtered_curr_state_comb_between_networks_2,filt_comb_walks_across_chains)\n",
    "\n",
    "#now we filter out comb of walks and combs of states where there is no possible walk from this current state \n",
    "meta_state_comb_to_walks_comb = filter(lambda _walks : len(_walks[1]) >0 ,state_comb_to_walks_comb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explanation of the results \"state_comb_to_walks_comb\" :\n",
    "\n",
    "state_comb_to_walks_comb[0] : states - state of every network\n",
    "\n",
    "state_comb_to_walks_comb[1] : walks - list of possible comb - every row contains :\n",
    "\n",
    "state_comb_to_walks_comb[1][i] : state j from state_comb_to_walks_comb[0] walk to state state_comb_to_walks_comb[1][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pick sub network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i=0\n",
    "\n",
    "# for s in meta_state_comb_to_walks_comb :\n",
    "#     i=i+1\n",
    "# print(i)\n",
    "# raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def build_long_state_vector(set_of_states,n_dim_of_chain):\n",
    "    def build_long_state(small_state,i) : \n",
    "        return [dim + i*n_dim_of_chain  for dim in small_state]\n",
    "        \n",
    "    state_vector = [build_long_state(small_state,i) for small_state,i in  zip(set_of_states,range(len(set_of_states)))]\n",
    "    flatten = [item for sublist in state_vector for item in sublist]\n",
    "    return frozenset(flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [00:00, 12284.57it/s]\n"
     ]
    }
   ],
   "source": [
    "size_of_pomegranate_network = 10000\n",
    "\n",
    "state_comb_to_walks_comb,_state_comb_to_walks_comb =itertools.tee(itertools.islice(meta_state_comb_to_walks_comb,size_of_pomegranate_network))\n",
    "\n",
    "state_comb_to_walks_comb_dict = {}\n",
    "\n",
    "with tqdm(size_of_pomegranate_network) as pbar : \n",
    "    for sample in _state_comb_to_walks_comb : \n",
    "        curr_state = build_long_state_vector(sample[0],n_dim_of_chain)\n",
    "        \n",
    "        next_possible = [build_long_state_vector(_next,n_dim_of_chain) for _next in sample[1]]\n",
    "        \n",
    "        state_comb_to_walks_comb_dict[curr_state] = next_possible\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# explore network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build the pomegranate network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def return_relevant_multi_distribution(state_vactor,prob_of_dim,n_dim_of_chain,n_of_chains,dist_option = \"discrete\") : \n",
    "    multi_hot_vector_state = np.zeros((n_of_chains*n_dim_of_chain,1))\n",
    "    multi_hot_vector_state[list(state_vactor)] = 1\n",
    "    \n",
    "    if dist_option == \"normal\" : \n",
    "        list_of_normal_dist = [NormalDistribution(dim[0],0.1) for dim in multi_hot_vector_state]\n",
    "    \n",
    "    if dist_option == \"discrete\" :\n",
    "        list_of_normal_dist = [DiscreteDistribution({dim[0]:prob_of_dim,(1-dim[0]):(1-prob_of_dim)}) for dim in multi_hot_vector_state]\n",
    "    return IndependentComponentsDistribution(list_of_normal_dist) \n",
    "\n",
    "def return_relevant_state(state_vector,prob_of_dim, n_dim_of_chain,n_of_chains) : \n",
    "    d = return_relevant_multi_distribution(state_vector,prob_of_dim, n_dim_of_chain,n_of_chains)\n",
    "    state_name = str(sorted(state_vector))\n",
    "    return State(d,state_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_vactor = frozenset({2, 5})\n",
    "# multi_hot_vector_state = np.zeros((n_of_chains*n_dim_of_chain,1))\n",
    "# multi_hot_vector_state[list(state_vactor)] = 1\n",
    "\n",
    "# dist = return_relevant_multi_distribution(state_vactor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi_hot_vector_state.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist.probability(np.array([[1., 1., 0., 0., 0., 1.]]))\n",
    "# dist.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for now we take random number of states :\n",
    "\n",
    "first = True\n",
    "\n",
    "with tqdm(size_of_pomegranate_network) as pbar : \n",
    "    state_holder ={}\n",
    "\n",
    "    markov_model = HiddenMarkovModel('first_try')\n",
    "    for sample in state_comb_to_walks_comb :\n",
    "        curr_state = build_long_state_vector(sample[0],n_dim_of_chain)\n",
    "\n",
    "        if curr_state not in state_holder.keys():\n",
    "            curr_pomp_state = return_relevant_state(curr_state,prob_of_dim, n_dim_of_chain,n_of_chains)\n",
    "            markov_model.add_states(curr_pomp_state)\n",
    "            state_holder[curr_state] = curr_pomp_state\n",
    "        else : \n",
    "            curr_pomp_state = state_holder[curr_state]\n",
    "\n",
    "        for _next in sample[1] : \n",
    "            next_possible = build_long_state_vector(_next,n_dim_of_chain)\n",
    "            if next_possible not in state_holder.keys():\n",
    "                next_pomp_state = return_relevant_state(next_possible,prob_of_dim, n_dim_of_chain,n_of_chains)\n",
    "                markov_model.add_states(next_pomp_state)\n",
    "                state_holder[next_possible] = next_pomp_state\n",
    "            else : \n",
    "                next_pomp_state = state_holder[next_possible]\n",
    "            \n",
    "            if first : \n",
    "                markov_model.add_transition(markov_model.start,curr_pomp_state,probability =0.5)\n",
    "                first = False\n",
    "            markov_model.add_transition(curr_pomp_state,next_pomp_state,probability =0.1)\n",
    "        pbar.update(1)\n",
    "    markov_model.add_transition(next_pomp_state,markov_model.end,probability =0.1)\n",
    "\n",
    "markov_model.bake()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"finish bake\")\n",
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# states = [state.name for state in markov_model.states]\n",
    "# Q = markov_model.dense_transition_matrix()\n",
    "\n",
    "# G = nx.MultiDiGraph()\n",
    "# labels={}\n",
    "# edge_labels={}\n",
    "\n",
    "# for i, origin_state in enumerate(states):\n",
    "#     for j, destination_state in enumerate(states):\n",
    "#         rate = Q[i][j]\n",
    "#         if rate > 0:\n",
    "#             G.add_edge(origin_state,\n",
    "#                        destination_state,\n",
    "#                        weight=rate,\n",
    "#                        label=\"{:.02f}\".format(rate))\n",
    "#             edge_labels[(origin_state, destination_state)] = label=\"{:.02f}\".format(rate)\n",
    "            \n",
    "# from nxviz import CircosPlot\n",
    "\n",
    "# c = CircosPlot(G)\n",
    "# c.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simulate samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_of_possible_rw = 50\n",
    "number_of_seqs = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_random_next_stage(_possible_next_steps,state_comb_to_walks_comb_dict,counter = 0) : \n",
    "    if counter == 50 : \n",
    "        return None\n",
    "    if len(_possible_next_steps) == 0 :\n",
    "        return None\n",
    "    \n",
    "    first_pick = random.choice(_possible_next_steps)\n",
    "    if first_pick in all_possible_states :\n",
    "        return first_pick\n",
    "    _possible_next_steps.remove(first_pick)\n",
    "    counter = counter + 1\n",
    "    return pick_random_next_stage(_possible_next_steps,state_comb_to_walks_comb_dict,counter)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes_in_model = [node.name for node in markov_model.graph.nodes]\n",
    "# isolated = [node.name for node in nx.algorithms.isolate.isolates(markov_model.graph)]\n",
    "\n",
    "all_possible_states = list(state_comb_to_walks_comb_dict.keys())\n",
    "# all_possible_states = [_state for _state in all_possible_states if str(sorted(_state)) in nodes_in_model ]\n",
    "# all_possible_states = [_state for _state in all_possible_states if str(sorted(_state)) not in isolated ]\n",
    "\n",
    "n_of_states_in_meta_network = len(all_possible_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = [] \n",
    "for i in range(number_of_seqs):\n",
    "    seq = []\n",
    "    random_state_idx = random.randint(1,n_of_states_in_meta_network)\n",
    "    curr_random_state = all_possible_states[random_state_idx-1]\n",
    "    seq.append(curr_random_state)\n",
    "    \n",
    "    for j in range(size_of_possible_rw) : \n",
    "        possible_next_steps = copy.copy(state_comb_to_walks_comb_dict[curr_random_state])\n",
    "        curr_random_state = pick_random_next_stage(possible_next_steps,state_comb_to_walks_comb_dict)\n",
    "        \n",
    "        if curr_random_state is None : \n",
    "            break\n",
    "            print(\"dude\")\n",
    "            random_state_idx = random.randint(1,n_of_states_in_meta_network)\n",
    "            curr_random_state = all_possible_states[random_state_idx-1]\n",
    "            \n",
    "        seq.append(curr_random_state)\n",
    "        \n",
    "    seqs.append(seq)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_G_dict_of_lists = nx.to_dict_of_lists(markov_model.graph)\n",
    "_G_dict_of_lists_clean = {k.name:[_v.name for _v in v] for k,v in _G_dict_of_lists.items()}\n",
    "\n",
    "_G = nx.from_dict_of_lists(_G_dict_of_lists_clean)\n",
    "adj_df = nx.to_pandas_adjacency(_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_multi_hot(state_set,n_dim_of_chain,n_of_chains) : \n",
    "    multi_hot_vector_state = np.zeros((n_of_chains*n_dim_of_chain,1))\n",
    "    multi_hot_vector_state[list(state_set)] = 1\n",
    "    return multi_hot_vector_state.T[0]\n",
    "\n",
    "def return_multi_hot_vectors(vectors,n_dim_of_chain,n_of_chains) :\n",
    "    return np.array([return_multi_hot(vector,n_dim_of_chain,n_of_chains) for vector in vectors])\n",
    "    \n",
    "# sampled_seqs = [return_multi_hot_vectors(random.choices(s,k=8),n_dim_of_chain,n_of_chains) for s in seqs]\n",
    "sampled_seqs = [return_multi_hot_vectors(s,n_dim_of_chain,n_of_chains) for s in seqs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq,p = markov_model.sample(path=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_model.predict(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def find_most_likely_states(markov_model,samples,k=3) : \n",
    "    emmisions_list = []\n",
    "    unique_samples =  [list(x) for x in set(tuple(x) for x in samples)]\n",
    "\n",
    "    for i,state in enumerate(markov_model.states) : \n",
    "        if state.distribution is not None : \n",
    "            emmisions_for_state = state.distribution.probability(unique_samples).tolist()\n",
    "            emmisions_for_state += [state.name,i]\n",
    "            emmisions_list.append(emmisions_for_state)\n",
    "        \n",
    "    emmisions_df = pd.DataFrame(columns=[str(s) for s in unique_samples]+[\"state\",\"state_idx\"],data=emmisions_list)\n",
    "    return emmisions_df.set_index([\"state\",\"state_idx\"]).apply(lambda x : x.argsort().argsort())\n",
    "\n",
    "def return_corresponding_states_to_samples(markov_model,seq) : \n",
    "    most_likely_states = find_most_likely_states(markov_model,seq)\n",
    "    \n",
    "    sample_to_state = {}\n",
    "\n",
    "    lowest_index = 0\n",
    "    for col in most_likely_states.columns : \n",
    "        _sample_to_states = most_likely_states[col].iloc[lowest_index:]\n",
    "        state,lowest_index = _sample_to_states.idxmax()\n",
    "        sample_to_state[col] = state\n",
    "    \n",
    "    return sample_to_state\n",
    "\n",
    "def create_continuous_observations(markov_model,seq,G) : \n",
    "    sample_to_state = return_corresponding_states_to_samples(markov_model,seq)\n",
    "    \n",
    "    new_seq = [] \n",
    "    for _curr_sample,_next_sample in zip(seq,seq[1:]) : \n",
    "        if (all(_curr_sample == _next_sample)):\n",
    "            continue\n",
    "        _curr_state = sample_to_state[str(_curr_sample.tolist())]\n",
    "        _next_state = sample_to_state[str(_next_sample.tolist())]\n",
    "        _simple_paths = nx.simple_paths.all_simple_paths(G,_curr_state,_next_state,cutoff=50)\n",
    "        return _simple_paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model with samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(markov_model.dense_transition_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "improvement = markov_model.fit(sampled_seqs,n_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25,25))\n",
    "transition_matrix = markov_model.dense_transition_matrix()\n",
    "sns.heatmap(transition_matrix, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_G_dict_of_lists = nx.to_dict_of_lists(markov_model.graph)\n",
    "_G_dict_of_lists_clean = {k.name:[_v.name for _v in v] for k,v in _G_dict_of_lists.items()}\n",
    "\n",
    "_G = nx.from_dict_of_lists(_G_dict_of_lists_clean)\n",
    "adj_df = nx.to_pandas_adjacency(_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25,25))\n",
    "sns.heatmap(adj_df.sort_index().sort_index(axis=1), cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_walks_seqs = []\n",
    "\n",
    "for _samples_seq in sampled_seqs:\n",
    "    _bach = [all_walks_seqs.append([str(np.where(_samples_seq[i-1])[0]),str(np.where(_samples_seq[i])[0]),1]) for i in range(1,len(_samples_seq))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_walks_seqs_df = pd.DataFrame(columns=[\"from\",\"to\",\"walk\"],data=all_walks_seqs)\n",
    "agg_walks_seqs_df = all_walks_seqs_df.groupby([\"from\",\"to\"]).sum()\n",
    "walks_seqs_df = agg_walks_seqs_df.reset_index().pivot(index=\"from\",columns=\"to\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25,25))\n",
    "sns.heatmap((walks_seqs_df>5).sort_index().sort_index(axis=1), cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "e_table = np.array([[1,5,12],[4,3,12],[6,1,3]])\n",
    "e_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_states_idx_per_sample = []\n",
    "k=2\n",
    "for states_per_obs in e_table.T :\n",
    "    best_states_idx_per_sample.append(states_per_obs.argsort()[-k:][::-1])\n",
    "best_states_idx_per_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from networkx.algorithms.shortest_paths import dijkstra_path,has_path\n",
    "_emission_table = e_table\n",
    "_top_e_per_state =best_states_idx_per_sample\n",
    "\n",
    "all_comb_of_possible_states = product(*_top_e_per_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __viterbi_fixed_states(model,comb) : \n",
    "    _curr_state = \"first\"\n",
    "    \n",
    "    for _state in comb : \n",
    "        _next_state = _state\n",
    "        dijkstra_path(b)\n",
    "        \n",
    "\n",
    "best_log_pos = -10000\n",
    "best_path = None\n",
    "for comb in all_comb_of_possible_states :\n",
    "    _log_pos_states = sum([_emission_table[state][obs] for state,obs in zip(comb,range(len(comb)))])\n",
    "    _best_path = __viterbi_fixed_states()\n",
    "    _log_pos_path = markov_model.log_probability(_best_path)\n",
    "    _log_pos = _log_pos_path + _log_pos_states\n",
    "\n",
    "    if _log_pos > best_log_pos :\n",
    "        best_log_pos = _log_pos\n",
    "        best_path = _best_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g = markov_model.graph\n",
    "l=[]\n",
    "for i,n in enumerate(g.nodes()) : \n",
    "    if i==3 :\n",
    "        pre = n\n",
    "        l.append(n)\n",
    "        continue\n",
    "    if has_path(g,pre,n) : \n",
    "        l.append(n)\n",
    "        pre = n \n",
    "         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def func(u, v, d):\n",
    "    edge_wt = d.get('weight', 1)\n",
    "    return math.exp(edge_wt)\n",
    "\n",
    "\n",
    "[s.name for s in dijkstra_path(g,l[1],l[6],weight=func)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.nodes.first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(self,source_state,target_state):\n",
    "    states = list(range(len(self.states)))\n",
    "    trans_p = self.dense_transition_matrix()\n",
    "    \n",
    "    max_length_path = len(states)\n",
    "    \n",
    "    V = [{}]\n",
    "    for st in states:\n",
    "        if source_state == st : \n",
    "            V[0][st] = {\"prob\": 1 , \"prev\": None}\n",
    "        else : \n",
    "            V[0][st] = {\"prob\": 0 , \"prev\": None}\n",
    "    \n",
    "    # Run Viterbi when t > 0\n",
    "    t=1\n",
    "    while(t < max_length_path):\n",
    "        V.append({})\n",
    "        for st in states:\n",
    "            max_tr_prob = V[t-1][states[0]][\"prob\"]*trans_p[states[0]][st]\n",
    "            prev_st_selected = states[0]\n",
    "            for prev_st in states[1:]:\n",
    "                tr_prob = V[t-1][prev_st][\"prob\"]*trans_p[prev_st][st]\n",
    "                if tr_prob > max_tr_prob:\n",
    "                    max_tr_prob = tr_prob\n",
    "                    prev_st_selected = prev_st\n",
    "                    \n",
    "            max_prob = max_tr_prob\n",
    "            V[t][st] = {\"prob\": max_prob, \"prev\": prev_st_selected}\n",
    "        \n",
    "        t += 1\n",
    "                    \n",
    "    opt = []\n",
    "    best_time_point_for_target = 0.0\n",
    "    max_prob = 0.0\n",
    "    previous = None\n",
    "    # Get most probable state and its backtrack\n",
    "    for time , time_data in enumerate(V):\n",
    "        target_prob = time_data[target_state][\"prob\"]\n",
    "        if target_prob > max_prob :\n",
    "            best_time_point_for_target = time+1\n",
    "            max_prob = target_prob\n",
    "    opt.append(target_state)\n",
    "    previous = target_state\n",
    "\n",
    "    # Follow the backtrack till the first observation\n",
    "    for t in range(best_time_point_for_target - 2, -1, -1):\n",
    "        opt.insert(0, V[t + 1][previous][\"prev\"])\n",
    "        previous = V[t + 1][previous][\"prev\"]\n",
    "\n",
    "    return opt,max_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt,max_prob = viterbi(markov_model,7,3)\n",
    "print(opt)\n",
    "print(np.log(max_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_model.dense_transition_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s.distribution.sample() for s in markov_model.states if (not ('start' in  s.name)) and (not ('end' in  s.name)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_model.states[2].distribution.sample()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
