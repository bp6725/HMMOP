{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import functools\n",
    "\n",
    "import pomegranate\n",
    "from pomegranate import HiddenMarkovModel ,State\n",
    "from pomegranate.distributions import IndependentComponentsDistribution\n",
    "from pomegranate.distributions import NormalDistribution\n",
    "\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build the meta network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params :\n",
    "n_dim_of_chain=8\n",
    "n_of_chains = 5\n",
    "possible_number_of_walks = [1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0,
     11,
     20,
     35,
     44
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 256/256 [00:00<00:00, 2251.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 256/256 [00:00<00:00, 3055.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 256/256 [00:00<00:00, 2999.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 256/256 [00:00<00:00, 3666.69it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 256/256 [00:00<00:00, 4066.80it/s]\n"
     ]
    }
   ],
   "source": [
    "def generate_all_binarys(n, arr, i): \n",
    "    if i==n :\n",
    "        all_binarys.append(np.nonzero(arr.copy())[0].tolist())\n",
    "        return \n",
    "\n",
    "    arr[i] = 0\n",
    "    generate_all_binarys(n, arr, i + 1)  \n",
    "\n",
    "    arr[i] = 1\n",
    "    generate_all_binarys(n, arr, i + 1) \n",
    "\n",
    "def build_IX_mock(n) :\n",
    "    imx_possible_walks = {}\n",
    "\n",
    "    for cell_idx in range(n):\n",
    "        number_of_walks = np.random.choice(possible_number_of_walks)\n",
    "        walks_idx = np.random.choice(range(n),number_of_walks,False)\n",
    "        imx_possible_walks[cell_idx] = walks_idx\n",
    "    return imx_possible_walks\n",
    "        \n",
    "def build_network_from_IX(n,all_binarys,imx_possible_walks) : \n",
    "    network_dic = {} #key:cell vec, value : all conncted cell vecs\n",
    "    pathway_network = {}\n",
    "    \n",
    "    for cell_vec in tqdm(all_binarys) : \n",
    "        if len(cell_vec) == 0  :\n",
    "            continue\n",
    "\n",
    "        possible_walk_for_idx_matrix = [imx_possible_walks[cell_idx] for cell_idx in cell_vec]\n",
    "        all_possible_walks_from_cell = [set(comb) for comb in itertools.product(*possible_walk_for_idx_matrix)]\n",
    "\n",
    "        network_dic[tuple(cell_vec)] = all_possible_walks_from_cell\n",
    "        pathway_network[tuple(cell_vec)] = np.random.choice([1,2,3,4,5],len(all_possible_walks_from_cell))\n",
    "    return network_dic,pathway_network\n",
    "\n",
    "def build_model_networks(n_of_chains,n,all_binarys,imx_possible_walks) : \n",
    "    model_networks = {}\n",
    "    pathway_networks = {}\n",
    "    for i in range(n_of_chains) : \n",
    "        _net_walks,_net_pathways_att = build_network_from_IX(n,all_binarys,imx_possible_walks)\n",
    "        model_networks[i] = _net_walks\n",
    "        pathway_networks[i] = _net_pathways_att\n",
    "    return model_networks,pathway_networks\n",
    "\n",
    "def build_pathways_mock(imx_possible_walks) : \n",
    "    hard_walk_to_pathways_map = {}\n",
    "    for vec in imx_possible_walks : \n",
    "        path = np.random.choice([1,2,3,4])\n",
    "        hard_cells_to_pathways_map[tuple(vec)] = path\n",
    "    return hard_walk_to_pathways_map\n",
    "\n",
    "all_binarys = [] \n",
    "generate_all_binarys(n_dim_of_chain,[None]*n_dim_of_chain,0)\n",
    "imx_possible_walks = build_IX_mock(n_dim_of_chain)\n",
    "model_networks,pathways_network = build_model_networks(n_of_chains,n_dim_of_chain,all_binarys,imx_possible_walks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the naive comb of states across chains\n",
    "all_curr_state_comb_between_networks = itertools.product(*[network for network in model_networks.values()])\n",
    "\n",
    "#we belive we can filter base on the real data\n",
    "filtered_curr_state_comb_between_networks = itertools.islice(all_curr_state_comb_between_networks,10000000)\n",
    "# filtered_curr_state_comb_between_networks = itertools.islice(all_curr_state_comb_between_networks,100)\n",
    "#now we need to find all possible combinations of walks : \n",
    "#we start by building all comb of walks across chains for all comb of states across chain\n",
    "all_walks_across_chains = map(lambda comb:[model_networks[net_idx][chain_state] for net_idx,chain_state in enumerate(comb)],filtered_curr_state_comb_between_networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_walk_in_path(x,_path):\n",
    "    return random.random() < 0.1\n",
    "\n",
    "def return_filtered_walks_per_curr_chain(_walks_per_curr_chain,path):\n",
    "    return list(map(lambda walk:list(filter(lambda x:is_walk_in_path(x,path),walk)),_walks_per_curr_chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#we now build diffrent stream for each pathway - **only comb where all the walks are in the same pathway are possible **\n",
    "def filter_comb_of_walks_across_chains(_walks_per_curr_comb):\n",
    "    all_combs_of_walks_all_paths = []\n",
    "    for _path in [1,2,3,4,5] : \n",
    "\n",
    "        #keep only walks in the pathway    \n",
    "        _walks_per_curr_comb_in_path = return_filtered_walks_per_curr_chain(_walks_per_curr_comb,_path)\n",
    "        \n",
    "        #its smart to filter out first comb of walks where there is at least one chain with no walk in this pathway :\n",
    "        if any([len(_walks)==0 for _walks in _walks_per_curr_comb_in_path]):\n",
    "            continue\n",
    "\n",
    "        _combs_of_walks = list(itertools.product(*_walks_per_curr_comb_in_path))\n",
    "        all_combs_of_walks_all_paths = all_combs_of_walks_all_paths +  _combs_of_walks\n",
    "        \n",
    "    return all_combs_of_walks_all_paths\n",
    "\n",
    "filt_comb_walks_across_chains = map(lambda _walks_per_curr_comb:filter_comb_of_walks_across_chains(_walks_per_curr_comb),all_walks_across_chains) \n",
    "\n",
    "#zip the combinations of states with the comb of walks \n",
    "state_comb_to_walks_comb = zip(filtered_curr_state_comb_between_networks,filt_comb_walks_across_chains)\n",
    "\n",
    "#now we filter out comb of walks and combs of states where there is no possible walk from this current state \n",
    "state_comb_to_walks_comb = filter(lambda _walks : len(_walks[1]) >0 ,state_comb_to_walks_comb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explanation of the results \"state_comb_to_walks_comb\" :\n",
    "\n",
    "state_comb_to_walks_comb[0] : states - state of every network\n",
    "\n",
    "state_comb_to_walks_comb[1] : walks - list of possible comb - every row contains :\n",
    "\n",
    "state_comb_to_walks_comb[1][i] : state j from state_comb_to_walks_comb[0] walk to state state_comb_to_walks_comb[1][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def build_long_state_vector(set_of_states):\n",
    "    def build_long_state(small_state,i) : \n",
    "        return [dim + i*n_dim_of_chain  for dim in small_state]\n",
    "        \n",
    "    state_vector = [build_long_state(small_state,i) for small_state,i in  zip(set_of_states,range(len(set_of_states)))]\n",
    "    flatten = [item for sublist in state_vector for item in sublist]\n",
    "    return frozenset(flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_state_comb_to_walks_comb = {}\n",
    "\n",
    "# with tqdm(100) as pbar : \n",
    "#     for sample in state_comb_to_walks_comb : \n",
    "#         curr_state = build_long_state_vector(sample[0])\n",
    "        \n",
    "#         next_possible = [build_long_state_vector(_next) for _next in sample[1]]\n",
    "        \n",
    "#         final_state_comb_to_walks_comb[curr_state] = next_possible\n",
    "#         pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "# with open(\"markov_network\",'wb') as f : \n",
    "#     pkl.dump(final_state_comb_to_walks_comb,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "# with open(\"markov_network\",'rb') as f : \n",
    "#     t = pkl.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pick the relvent states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def return_relevant_multi_distribution(state_vactor) : \n",
    "    multi_hot_vector_state = np.zeros((n_of_chains*n_dim_of_chain,1))\n",
    "    multi_hot_vector_state[list(state_vactor)] = 1\n",
    "    list_of_normal_dist = [NormalDistribution(dim,1) for dim in multi_hot_vector_state]\n",
    "    return IndependentComponentsDistribution(list_of_normal_dist) \n",
    "\n",
    "def return_relevant_state(state_vector) : \n",
    "    d = return_relevant_multi_distribution(state_vector)\n",
    "    state_name = str(sorted(state_vector))\n",
    "    return State(d,state_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [03:41, 45.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# for now we take random number of states :\n",
    "first = True\n",
    "how_much_to_take = 1000\n",
    "\n",
    "with tqdm(how_much_to_take) as pbar : \n",
    "    state_holder ={}\n",
    "\n",
    "    markov_model = HiddenMarkovModel('first_try')\n",
    "    for sample,_ in zip(state_comb_to_walks_comb,range(how_much_to_take)) : \n",
    "        curr_state = build_long_state_vector(sample[0])\n",
    "\n",
    "        if curr_state not in state_holder.keys():\n",
    "            curr_pomp_state = return_relevant_state(curr_state)\n",
    "            markov_model.add_states(curr_pomp_state)\n",
    "            state_holder[curr_state] = curr_pomp_state\n",
    "        else : \n",
    "            curr_pomp_state = state_holder[curr_state]\n",
    "\n",
    "        for _next in sample[1] : \n",
    "            next_possible = build_long_state_vector(_next)\n",
    "            if next_possible not in state_holder.keys():\n",
    "                next_pomp_state = return_relevant_state(next_possible)\n",
    "                markov_model.add_states(next_pomp_state)\n",
    "                state_holder[next_possible] = next_pomp_state\n",
    "            else : \n",
    "                next_pomp_state = state_holder[next_possible]\n",
    "            \n",
    "            if first : \n",
    "                markov_model.add_transition(markov_model.start,curr_pomp_state,1)\n",
    "                first = False\n",
    "            markov_model.add_transition(curr_pomp_state,next_pomp_state,1)\n",
    "        pbar.update(1)\n",
    "    markov_model.add_transition(next_pomp_state,markov_model.end,1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "baked_markov_model = markov_model.bake()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "finished",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-3c6acff0fc61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"finished\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mException\u001b[0m: finished"
     ]
    }
   ],
   "source": [
    "raise Exception(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sampled_seqs.pkl\",'rb') as f : \n",
    "    sampled_seqs = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_model = markov_model.fit(sampled_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-inf, None)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markov_model.viterbi(sampled_seqs[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the distrbution to the real data - \n",
    "## find close samples - by my own function\n",
    "## fit by thet samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best trajc"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
